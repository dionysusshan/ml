{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPopKPytC3WEuv4w2o1/11X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dionysusshan/ml/blob/main/Averaging_method_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb3YLPOX613e",
        "outputId": "ec3d3214-0f66-4659-d00d-2df0bfe4b69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "     AQI-IN     PM25    PM10      PM1  Temp(cel)      Hum    Noise  TVOC(ppm)  \\\n",
            "0  114.3580  64.1700  85.939  60.4000    22.6070  98.2770  48.3450     0.0090   \n",
            "1   95.4740  57.2600  75.377  53.9740    22.3730  95.7710  48.3700     0.0100   \n",
            "2   78.3800  47.0450  59.341  44.5980    30.2404  85.4160  48.0780     0.0104   \n",
            "3   65.0780  38.7242  47.500  37.3220    28.1220  65.4868  50.8440     0.0080   \n",
            "4   57.6288  35.5980  42.358  33.3266    30.9720  63.4980  50.1188     0.0100   \n",
            "\n",
            "   CO(ppm)  CO2(ppm)  ...  O3(ppm)  AQI-IN(F)  AQI-IN(s)      CI    VI  \\\n",
            "0    0.392   482.552  ...   0.0210   114.3580   114.3580  9.8730  10.0   \n",
            "1    0.454   486.747  ...   0.0230    95.4740    95.4740  9.0060  10.0   \n",
            "2    0.667   482.067  ...   0.0234    82.1280    78.3800  9.0000  10.0   \n",
            "3    0.680   458.754  ...   0.0260    79.4324    65.0780  9.0272  10.0   \n",
            "4    0.750   455.927  ...   0.0240    76.1730    57.6288  9.0000  10.0   \n",
            "\n",
            "   particle count(0.3)  particle count(0.5)  particle count(1.0)  \\\n",
            "0           19366.7090             2500.933             365.0550   \n",
            "1           13269.0286             2267.409             320.4160   \n",
            "2           14244.0000             1777.883             174.1722   \n",
            "3           11881.1670             1255.455             170.9170   \n",
            "4           10547.3434             1147.922             141.9160   \n",
            "\n",
            "   particle count(3.0)  particle count(5.0)  \n",
            "0             152.1880             0.097000  \n",
            "1              78.9302             0.169000  \n",
            "2              93.7710             0.084000  \n",
            "3              64.2830             0.116667  \n",
            "4              51.9110             0.116667  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "Mean Squared Error: 0.002457356843363015\n",
            "R^2 Score: -2.588983178265579\n",
            "Models and averaged predictions saved.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Step 1: Load Data\n",
        "# Replace 'your_dataset.csv' with the path to your CSV file\n",
        "file_path = '/content/sample_data/imputed_dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Original Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 2: Preprocess Data\n",
        "# Assume the last column is the target variable\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features (optional but recommended for consistency across models)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Step 3: Define the Models\n",
        "lr_model = LinearRegression()\n",
        "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
        "svr_model = SVR(kernel='rbf')\n",
        "\n",
        "# Step 4: Train the Models\n",
        "lr_model.fit(X_train, y_train)\n",
        "knn_model.fit(X_train, y_train)\n",
        "svr_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make Predictions\n",
        "lr_pred = lr_model.predict(X_test)\n",
        "knn_pred = knn_model.predict(X_test)\n",
        "svr_pred = svr_model.predict(X_test)\n",
        "\n",
        "# Step 6: Average the Predictions\n",
        "average_pred = (lr_pred + knn_pred + svr_pred) / 3\n",
        "\n",
        "# Step 7: Evaluate the Averaged Predictions\n",
        "mse = mean_squared_error(y_test, average_pred)\n",
        "r2 = r2_score(y_test, average_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R^2 Score: {r2}\")\n",
        "\n",
        "# Optional: Save the models and the averaged predictions\n",
        "import joblib\n",
        "joblib.dump(lr_model, 'lr_model.pkl')\n",
        "joblib.dump(knn_model, 'knn_model.pkl')\n",
        "joblib.dump(svr_model, 'svr_model.pkl')\n",
        "np.save('average_predictions.npy', average_pred)\n",
        "print(\"Models and averaged predictions saved.\")\n"
      ]
    }
  ]
}